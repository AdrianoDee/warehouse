{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import os\n",
    "import multiprocessing\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../merged/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_helper(slice_entries, file_entries, file_curr, entry_curr):\n",
    "    if slice_entries <= file_entries[file_curr] - entry_curr:\n",
    "        return [file_curr, slice_entries + entry_curr]\n",
    "    elif file_curr == len(file_entries) - 1:\n",
    "        return [file_curr, file_entries[-1]]\n",
    "    else:\n",
    "        return partition_helper(slice_entries - file_entries[file_curr] + entry_curr, file_entries, file_curr + 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(files, n_processes):\n",
    "    file_entries = [file.num_entries for file in files]\n",
    "    slice_entries = math.ceil(sum(file_entries) / n_processes)\n",
    "    slices = []\n",
    "    file_start = 0\n",
    "    entry_start = 0\n",
    "    while not bool(slices) or slices[-1][-1] != (file_entries[-1]):\n",
    "        slices.append([file_start, entry_start] + partition_helper(slice_entries, file_entries, file_start, entry_start))\n",
    "        file_start = slices[-1][-2]\n",
    "        entry_start = slices[-1][-1]\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_one_file(candidate_trees, candidate_slices, ups_trees, ups_slices, index, target_dir):\n",
    "    candidate_data = []\n",
    "    ups_data = []\n",
    "    for i in range(candidate_slices[index][0], candidate_slices[index][2] + 1):\n",
    "        candidate_data.append(candidate_trees[i].arrays(\n",
    "            [key for key in candidate_trees[i].keys() if not key.endswith(\"_p4\")],\n",
    "            entry_start=candidate_slices[index][1] if i == candidate_slices[index][0] else None,\n",
    "            entry_stop=candidate_slices[index][3] if i == candidate_slices[index][2] else None,\n",
    "            library=\"pd\"))\n",
    "    for i in range(ups_slices[index][0], ups_slices[index][2] + 1):\n",
    "        ups_data.append(ups_trees[i].arrays(\n",
    "            [key for key in ups_trees[i].keys() if not key.endswith(\"_p4\")],\n",
    "            entry_start=ups_slices[index][1] if i == ups_slices[index][0] else None,\n",
    "            entry_stop=ups_slices[index][3] if i == ups_slices[index][2] else None,\n",
    "            library=\"pd\"))\n",
    "    file = uproot.recreate(target_dir + \"/file\" + str(index) + \".root\")\n",
    "    file.mkdir(\"rootuple\")\n",
    "    file[\"rootuple/CandidateTree\"] = pd.concat(candidate_data)\n",
    "    file[\"rootuple/UpsTree\"] = pd.concat(ups_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redistribute(path, n_files):\n",
    "    target_dir = \"data/\" + str(n_files) + \"_files\"\n",
    "    os.mkdir(target_dir)\n",
    "    candidate_trees = [uproot.open(path=path + filename  + \":rootuple/CandidateTree\") for filename in sorted(os.listdir(path))]\n",
    "    candidate_slices = partition(candidate_trees, n_files)\n",
    "    ups_trees = [uproot.open(path=path + filename+ \":rootuple/UpsTree\") for filename in sorted(os.listdir(path))]\n",
    "    ups_slices = partition(ups_trees, n_files)\n",
    "    result = multiprocessing.Manager().list()\n",
    "    processes = []\n",
    "    for i in range(n_files):\n",
    "        p = multiprocessing.Process(target=write_one_file, args=[candidate_trees, candidate_slices, ups_trees, ups_slices, i, target_dir])\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: impossibile creare la directory \"data\": File giÃ  esistente\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!rm -rf data/32_files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/lustre/cms/store/user/slezki/ykk_DataRunII_UltraLegacy_miniAODv2_v1/files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redistribute(path,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
